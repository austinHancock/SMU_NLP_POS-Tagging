{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Austin Hancock\n",
    "\n",
    "## MSDS 7337 - Section 401\n",
    "## Homework - Week 4\n",
    "[Data Science @ Southern Methodist University](https://datascience.smu.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Description](#Description)\n",
    "* [Tools](#Tools)\n",
    "* [Question-1](#Question-1)\n",
    "* [Question-2](#Question-2)\n",
    "* [Question-3](#Question-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"Description\"></a>Description\n",
    "For the HW-4 assignment I will be addressing the following:\n",
    "\n",
    "    - Run POS tagger on two sentences\n",
    "    - Run different POS tagger on same sentences\n",
    "    - Run POS tagger on a sentence from a news article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"Tools\"></a>Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.17134-SP0\n",
      "Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]\n",
      "NLTK 3.2.4\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import nltk; print(\"NLTK\", nltk.__version__)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import UnigramTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"Question-1\"></a>Question-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one of the part-of-speech (POS) taggers available in Python\n",
    "\n",
    "    - Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. \n",
    "    - Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "['A', 'creative', 'man', 'is', 'motivated', 'by', 'the', 'desire', 'to', 'achieve', ',', 'not', 'by', 'the', 'desire', 'to', 'beat', 'others', '.']\n",
      "\n",
      "POS tags:\n",
      "[('A', 'DT'), ('creative', 'JJ'), ('man', 'NN'), ('is', 'VBZ'), ('motivated', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('desire', 'NN'), ('to', 'TO'), ('achieve', 'VB'), (',', ','), ('not', 'RB'), ('by', 'IN'), ('the', 'DT'), ('desire', 'NN'), ('to', 'TO'), ('beat', 'VB'), ('others', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Long-sentence tagging\n",
    "\n",
    "text = word_tokenize(\"A creative man is motivated by the desire to achieve, not by the desire to beat others.\")\n",
    "print(\"Original sentence:\")\n",
    "print(text)\n",
    "print()\n",
    "text_POS = nltk.pos_tag(text)\n",
    "print(\"POS tags:\")\n",
    "print(text_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "['Buffalo', 'buffalo', 'Buffalo', 'buffalo', 'buffalo', 'buffalo', 'Buffalo', 'buffalo', '.']\n",
      "\n",
      "POS tags:\n",
      "[('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Short-sentence tagging\n",
    "\n",
    "text = word_tokenize(\"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\")\n",
    "print(\"Original sentence:\")\n",
    "print(text)\n",
    "print()\n",
    "text_POS = nltk.pos_tag(text)\n",
    "print(\"POS tags:\")\n",
    "print(text_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird sentence right? Seems like a typo but this is actually a grammatically correct sentence. You can read it as \"Buffalo from the city Buffalo that other buffalo from the city Buffalo bully [themselves] bully buffalo from the city Buffalo\". https://en.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The long sentence was correctly tagged with an accuracy of 100%.\n",
    "The short sentence was correctly tagged with an accuracy of 75%, incorrectly identifying two of the eight parts-of-speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why was the longer sentence able to correctly identify all parts-of-speech tags but the shorter sentence ran into problems? To investigate, lets start by looking at what the correct POS tags for the sentence should have been."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.<br />\n",
    "  NNP     NN      NNP     NN      VRB     VRB     NNP     NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that two of the words were tagged as nouns that should have been verbs. Finding the correct tags is a good start. But what caused these words to be tagged incorrectly? The next step we need to do with a sentence replete with homonyms such as this, is to find out what this sentence is actually saying. To do this, let's see what the different parts-of-speech the word \"buffalo\" can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('american_bison.n.01')\n",
      "large shaggy-haired brown bison of North American plains\n",
      "\n",
      "Synset('buffalo.n.02')\n",
      "a city on Lake Erie in western New York (near Niagara Falls)\n",
      "\n",
      "Synset('buffalo.n.03')\n",
      "meat from an American bison\n",
      "\n",
      "Synset('old_world_buffalo.n.01')\n",
      "any of several Old World animals resembling oxen including, e.g., water buffalo; Cape buffalo\n",
      "\n",
      "Synset('buffalo.v.01')\n",
      "intimidate or overawe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "syns = wordnet.synsets('buffalo')\n",
    "for defs in syns:\n",
    "    print(defs)\n",
    "    print(defs.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using Princeton WordNet, you can see that there are five different definitions of the word 'buffalo'; four nouns and one verb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uncommon use of the word 'buffalo' as a verb meaning 'to intimidate' along with the structure of the sentence in terms of both length (short) and variety of tags (75% nouns), the tagger was unable to properly tag the parts-of-speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"Question-2\"></a>Question-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "\n",
    "    - Does it produce the same or different output?\n",
    "    - Explain any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training set\n",
    "data = treebank.tagged_sents()\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence Tagging:\n",
      "[('A', 'DT'), ('creative', 'JJ'), ('man', 'NN'), ('is', 'VBZ'), ('motivated', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('desire', 'NN'), ('to', 'TO'), ('achieve', 'VB'), (',', ','), ('not', 'RB'), ('by', 'IN'), ('the', 'DT'), ('desire', 'NN'), ('to', 'TO'), ('beat', 'VB'), ('others', 'NNS'), ('.', '.')]\n",
      "\n",
      "Performance of Unigram tagger:\n",
      "[('A', 'DT'), ('creative', None), ('man', 'NN'), ('is', 'VBZ'), ('motivated', None), ('by', 'IN'), ('the', 'DT'), ('desire', 'NN'), ('to', 'TO'), ('achieve', 'VB'), (',', ','), ('not', 'RB'), ('by', 'IN'), ('the', 'DT'), ('desire', 'NN'), ('to', 'TO'), ('beat', 'VB'), ('others', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Long sentence\n",
    "text = word_tokenize(\"A creative man is motivated by the desire to achieve, not by the desire to beat others.\")\n",
    "print(\"Original sentence Tagging:\")\n",
    "print(nltk.pos_tag(text))\n",
    "print()\n",
    "\n",
    "# Unigram Tag\n",
    "ut = UnigramTagger(train_data)\n",
    "print(\"Performance of Unigram tagger:\")\n",
    "print(ut.tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence Tagging:\n",
      "[('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('.', '.')]\n",
      "\n",
      "Performance of Unigram tagger:\n",
      "[('Buffalo', None), ('buffalo', None), ('Buffalo', None), ('buffalo', None), ('buffalo', None), ('buffalo', None), ('Buffalo', None), ('buffalo', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Short sentence\n",
    "text = word_tokenize(\"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\")\n",
    "print(\"Original sentence Tagging:\")\n",
    "print(nltk.pos_tag(text))\n",
    "print()\n",
    "\n",
    "# Unigram Tag\n",
    "ut = UnigramTagger(train_data)\n",
    "print(\"Performance of Unigram tagger:\")\n",
    "print(ut.tag(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second Tagger that I ran was a Unigram Tagger. This tagger was built on test data from the treebank corpus. For both the long-sentence and short-sentence tasks, the Unigram Tagger performed less well than the POS tagger I used in question 1. \n",
    "\n",
    "For the long-sentence the Unigram Tagger was not able to find the POS tags for two words (denoted by the POS tag 'None'). This occurs when the token we are evaluating from the test sentence is not found in the training set. As an even more salient example, the short-sentence did not find any POS-tags. This problem, however, is not typical as all of the tokens in the test sentence are the word 'buffalo', and therefore is highly relient on that token being present in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"Question-3\"></a>Question-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a news article from this week's news, find a random sentence of at least 10 words.\n",
    "    \n",
    "    - Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "    - Now run the same sentence through both taggers that you implemented for questions 1 and 2. Did either of the taggers\n",
    "    produce the same results as you had created manually?\n",
    "    - Explain any differences between the two taggers and your manual tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentence I will be looking at for question three comes from the Business Insider article 'This speculative SpaceX timeline reveals roughly when, where, and how Elon Musk plans to colonize Mars'.\n",
    "\n",
    "    - Musk was frustrated that NASA was not doing more to get people to the red planet — and concerned that a backup plan for humanity was not being developed (for when Earth becomes an uninhabitable wasteland).\n",
    "    - NNP VBD VBN IN NNP VBD RB VBG JJR TO VB NNS TO DT JJ NN : CC VBD IN DT JJ NN IN NN VBD RB VBG VBN ( IN WRB NNP VBZ DT JJ NN ) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagger:\n",
      "[('Musk', 'NNP'), ('was', 'VBD'), ('frustrated', 'VBN'), ('that', 'IN'), ('NASA', 'NNP'), ('was', 'VBD'), ('not', 'RB'), ('doing', 'VBG'), ('more', 'JJR'), ('to', 'TO'), ('get', 'VB'), ('people', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('red', 'JJ'), ('planet', 'NN'), ('-', ':'), ('and', 'CC'), ('concerned', 'VBD'), ('that', 'IN'), ('a', 'DT'), ('backup', 'NN'), ('plan', 'NN'), ('for', 'IN'), ('humanity', 'NN'), ('was', 'VBD'), ('not', 'RB'), ('being', 'VBG'), ('developed', 'VBN'), ('(', '('), ('for', 'IN'), ('when', 'WRB'), ('Earth', 'NNP'), ('becomes', 'VBZ'), ('an', 'DT'), ('uninhabitable', 'JJ'), ('wasteland', 'NN'), (')', ')'), ('.', '.')]\n",
      "\n",
      "Unigram Tagger:\n",
      "[('Musk', None), ('was', 'VBD'), ('frustrated', None), ('that', 'IN'), ('NASA', None), ('was', 'VBD'), ('not', 'RB'), ('doing', 'VBG'), ('more', 'JJR'), ('to', 'TO'), ('get', 'VB'), ('people', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('red', 'JJ'), ('planet', None), ('-', ':'), ('and', 'CC'), ('concerned', 'VBN'), ('that', 'IN'), ('a', 'DT'), ('backup', None), ('plan', 'NN'), ('for', 'IN'), ('humanity', None), ('was', 'VBD'), ('not', 'RB'), ('being', 'VBG'), ('developed', 'VBD'), ('(', None), ('for', 'IN'), ('when', 'WRB'), ('Earth', None), ('becomes', 'VBZ'), ('an', 'DT'), ('uninhabitable', None), ('wasteland', None), (')', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS Tagger\n",
    "text = word_tokenize(\"Musk was frustrated that NASA was not doing more to get people to the red planet - and concerned that a backup plan for humanity was not being developed (for when Earth becomes an uninhabitable wasteland).\")\n",
    "print(\"POS Tagger:\")\n",
    "print(nltk.pos_tag(text))\n",
    "print()\n",
    "\n",
    "# Unigram Tagger\n",
    "print(\"Unigram Tagger:\")\n",
    "print(ut.tag(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nltk POS tagger produced one different tagg than my manual tags. \n",
    "    \n",
    "    - Manual: ('backup', 'JJ') \n",
    "    - POS_Tag: ('backup', 'NN')\n",
    "    \n",
    "Since 'backup' was talking about a 'backup plan', I was tagging it as an adjective, but the tagger chose noun. This word can be used as both an adjective and a noun, but since the noun part-of-speech is much more frequent, not to mention the only POS in Wordnet, I should have tagged this as a noun. This error in judgement on my part is an excellent example of how well curated POS tagsets along with a good tagger function can better interpret POS tags at scale.\n",
    "\n",
    "As expected, the Unigram tagger performed much more poorly than the nltk POS tagger. Of the 39 tokens, 11 were missing from the training set resulting in a tag of 'None'. As discussed earlier, this relies heavily on the training-set used. Beyond that, I am not surprised to see that the tokens 'Musk' and 'NASA' were not found since these are proper nouns and would most likely require a specific type of training-set, such as ones built under the categories of news, space, or technology. In addition to the missing tags, the unigram tagger differed from both my manual tag and the nltk tag for the word 'developed':\n",
    "\n",
    "    - Manual: ('developed', 'VBN')\n",
    "    - POS_tag: ('developed', 'VBN')\n",
    "    - Unigram: ('developed', 'VBD')\n",
    "    \n",
    "Both my manual tag and the pos_tag list the word as a past participle while the Unigram tag identified the token as a past tense form of a verb. The unigram training-set most likely had a past tense form of the token 'developed' since that is more common than a past participle. However, the POS_tag was able to determine that the word 'developed' in this sentence did not have a tense and therefore correctly tagged the token as a past participle. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
